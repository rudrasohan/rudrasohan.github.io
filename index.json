[{"authors":["admin"],"categories":null,"content":"I am a final year graduate-student at IIT Kharagpur traversing the distance between intuitions and equations. Pondering over life, sometimes I find comfort on the printed page and sometimes in a tête-à-tête. Occasionally I also pen things around.\n","date":1586822400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1598313600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://rudrasohan.github.io/author/sohan-rudra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sohan-rudra/","section":"authors","summary":"I am a final year graduate-student at IIT Kharagpur traversing the distance between intuitions and equations. Pondering over life, sometimes I find comfort on the printed page and sometimes in a tête-à-tête.","tags":null,"title":"Sohan Rudra","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://rudrasohan.github.io/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://rudrasohan.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Sohan Rudra"],"categories":["Casual"],"content":"Heavy breathing, beads of sweat dripping from my temple, hands gripping the moss-covered boulder as I pulled up myself, stepping carefully on the weakened bamboos creaking under my feet. As I stood atop the summit gripping tightly on the worn-out fence, my senses were overwhelmed by the scene underneath. The gleaming blue elixir coursing through the rocky creek surrounded by towering rock-giants and lush green pillars were ameliorating my fatigue. “Hey, we are here !!!”, shrieked Rathore, and I was back out of my immersion. The entire group was here, patting each other’s back for conquering Mawryngkhang. Sitting down, munching on some crackers we rambled and joked.\nI did not realize when fatigue dosed my eyes, and I began reminiscing about how just three days back I was trying my level best to avoid this trip. Everything is scary when you are not in control or better not in the illusion of being in control.\n\u0026hellip;\nThe story continues here\n","date":1586822400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598313600,"objectID":"9442ddf4b66a3b41951c5c59136a4dd7","permalink":"https://rudrasohan.github.io/post/college-trip/","publishdate":"2020-04-14T00:00:00Z","relpermalink":"/post/college-trip/","section":"post","summary":"My experiences with uncertainty in life and friendships, masquerading in the form of a travelogue.","tags":["Friendship"],"title":"College Trip","type":"post"},{"authors":null,"categories":null,"content":"Car-Racing is a sport which requires ultra-precise reflexes along with the understanding of harmony between the driver and the race-car. In essence, it can provide a challenging testbed for testing the limits of an autonomous driving agent. Building upon this philosophy and also observing the budding popularity of TORCS in RL community, we created MADRaS which can provide a proper environment for Multi-Agent Reinforcement Learning.\nMADRaS provide an OpenAI Gym interface for the TORCS environment along with support for parallelism. A user can create their custom environment selecting from a plethora of TORCS tracks and vehicles using our interface which melds this into a python API. The entire simulator can easily be configured with a single file. Additionally, we also bring support for randomized environment creation, custom control schemes and custom traffic agents to help create diverse scenarios.\nThe main crux of MADRaS boils down to its Multi-Agent capabilities. The entire Multi-Agent system has been designed following the guidelines provided by the BAIR lab at UC Berkely. Each agent can interact separately with the simulator and with the other agents. Each agent has a communication overhead, and the entire communication network can be reconfigured by a single configuration file.\nThe entire project is open-sourced under the AGPL-3.0 license.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b15e1bf2cf3c31f63884a03d54ef13e1","permalink":"https://rudrasohan.github.io/project/madras/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/madras/","section":"project","summary":"MADRaS is a Multi-Agent Autonomous Driving Simulator built on top of TORCS. The simulator can be used to test autonomous vehicle algorithms both heuristic and learning based on an inherently multi agent setting.","tags":["Simulation","Reinforcement Learning"],"title":"MADRaS","type":"project"},{"authors":["Sohan Rudra","G Rahul Kranti Kiran","Indu Kant Deo","Sanskar Agrawal","Siddhant Haldar","Het Shah,","Harsh Maheshwari","Aditya Rathore","Poojan Shah","Ashwin Nehete","Debashish Chakravarty"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1551052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551052800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://rudrasohan.github.io/publication/conference-paper/","publishdate":"2019-03-28T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"The system paper for Eklavya 6.0. A bot capable of autonomously traversing a grassy landscape along with obstacle avoidance.","tags":["Robotics"],"title":"Design and Implementation of Autonomous Ground Vehicle for Constrained Environments","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://rudrasohan.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" Frenet Planner is a motion planning algorithm for car-like vehicles. For a given state of a car the planner samples posssible next states in the Frenet Frame and connects them. The algorithm uses simple splines for connecting various the points.\nThe splines are computed using Kinematic equations of velocities and positions with respect to time. The paths are composed of two different spliens longitudinal and transversal. The longitudinal splines are characterized by velocities where as the transversal splines are characterized by position. After the relvant splines are computed a routine filters out the splines which are not following the kinematic and saftey constraits. Finally the filtered paths are evaluated on a certain objective function which minimizes jerk in tranjectory and the most optimal one is selected for execution.\nFinally we transfer the path to the path tracker algorithm which generates required velocities for the low level controller.\n","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"5459ca218723894eea0627f0494d0f82","permalink":"https://rudrasohan.github.io/project/frenet-planner/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/project/frenet-planner/","section":"project","summary":"Implementation of Frenet Optimal Trajectory planning for motion planning of a four wheeled autonomous vehicle.","tags":["Simulation","Robotics"],"title":"Frenet Planner","type":"project"},{"authors":null,"categories":null,"content":"Reinforcement Learning is a tool which helps an artificial agent to \u0026ldquo;Learn by Doing\u0026rdquo;. The agents interact with the system and learn the ropes becoming better in each iteration. Most of RL research focusses on training agents in simulations as during early iterations of learning some of the agent\u0026rsquo;s actions may be harmful to itself or the user or its surroundings. But many-a-times it\u0026rsquo;s not possible to train in simulation owing to either difficulty in the representation of the environment virtually or due to the sheer gap in generalization performance. Hence, in such cases, Safe-Reinforcement learning algorithms help train the agents considering the system constraints.\nThere are several ways to enforce AI Saftey. In this work, we have selected two aspects of safety, Performance Bonds and Constraint Optimization.\nOne aspect of AI-Saftey could be described in terms of algorithmic performance, i.e. the actions of an agent are considered safe until the overall performance lies above a certain threshold. Using techniques like Importance Sampling one can estimate the agent\u0026rsquo;s policy performance before it is executed.\nThe other way to enforce safety is by making sure the algorithm makes updates which satisfy certain constraints. The vast literature on constraint optimization boasts several techniques which ensure that the policy transitions only from one safe state into the next. For these methods, one needs to set up functional forms for each of the constraints.\nWe see that these techniques ameliorate the issues with safety-aware training.\n","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"e42e2acd688e22511e8d8468f974affa","permalink":"https://rudrasohan.github.io/project/safe-reinforcement-learning/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/project/safe-reinforcement-learning/","section":"project","summary":"Implemented and tested various Constraint Optimization based Safe Reinforcement Learning algorithms for autonomous control and navigation on simulations.","tags":["Deep Learning","Reinforcement Learning"],"title":"Safe RL","type":"project"}]